------------------------------------------------------------------------------------------
			               DATA INITIALIZATION
------------------------------------------------------------------------------------------

(1)  Set up the list of images
       imglist=setup_imglist(image_names, img_path);
       where, image_names : list of image names
        	     img_path: the path to the directory containing the images

 (2) Read annotations
       annot=read_img_annotations(image_names, imglist, annot_path);
       where, image_names: list of image names
       	      annot_path: the path to the directory containing the annotations

------------------------------------------------------------------------------------------
		                CONSTRUCTION OF POSLISTS
------------------------------------------------------------------------------------------

(1) part=sample_kposelets(annot,imglist,unit_dims,K,NUM_CANDIDATES);
       where, unit_dims: the desired aspect rations [h w], e.g. [96 64;64 64]
        	      K: numbers of parts
        	      NUM_CANDIDATES: number of candidate K-poselets

(2) [Visualization] browse_kposelets(annot,imglist,part,i);
      where, i: index into the candidates, i=1,...,NUM_CANDIDATES


------------------------------------------------------------------------------------------
                                  TRAINING EACH POSELET
------------------------------------------------------------------------------------------

(1) model = train_kposelet(part, annot, negimglist, imglist, name, kpid, index_in_part);
    part, annot, imglist are the same as above.
    negimglist is a list of negative images. 
    name serves as an identifier for a *set* of kposelets. For instance if you are training
    kposelets on PASCAL you can name it "PASCAL"
    kpid serves as an identifier for a particular kposelet in the set. During detection, the
    output will record the kpid for each detection.
    index_in_part is the index in part of the kposelet you want to train.

--------------------------------------------------------------------------------------------
                                  KEYPOINT MODELS
--------------------------------------------------------------------------------------------

(1)  kps_models = keypoint_klet(annot,part)
        where kps_models contains the keypoint model for each poselet

(2) coords = predict_keypoints(box, kps_model)

(3) bbox_models=bbox_klet(annot,part)



--------------------------------------------------------------------------------------------
								DETECTING K-POSELETS
--------------------------------------------------------------------------------------------
(1) detections = collect_detections_on_imglist(imglist, models, 3, start_id, end_id, use_sse);
	where start_id is the starting index and end_id is the ending index in imglist



--------------------------------------------------------------------------------------------
								AMP SELECTION
--------------------------------------------------------------------------------------------
After computing detections on val:
(1) Find labels of activations
Using torsos:
[labels, index] = find_labels_of_activations(annot, imglist, detections, kps_models, [1 4 7 10], 0.5);
Using bounding boxes:
[labels, index] = find_labels_of_activations_bbox(annot, imglist, detections, bbox_models, 0.5);

(2) Get precision-recall mapping
prec_rec = precision_recall_for_klets(detections, labels);
Use torsos to get torso_prec_rec, bounding boxes to get bbox_prec_rec;

(3) AMP selection
max_score=compute_max_score(detections, index);
[C, amp] = amp_selection(max_score, prec_rec, 200);

(4) Select detections
detections=select_detections(detections, ismember(detections.kpids, C));


--------------------------------------------------------------------------------------------
								CLUSTERING
--------------------------------------------------------------------------------------------
(1) clusters = cluster_activations_agglomerative(detections, kps_models, torso_prec_rec, [1 4 7 10], 0.3);



--------------------------------------------------------------------------------------------
								STAGE 2 MODELS
--------------------------------------------------------------------------------------------
(1) Train stage 2 models:
stage2model = train_stage2_detection_top_withbbox(training_image_ids, clusters, detections,...
							 kps_models, torso_prec_rec, bbox_prec_rec, imglist, annot, bbox_models, C);

(2) Test stage 2 models:
[scores, bounds, idx]=test_stage2_detection_top(clusters, detections, kps_models, ...
							torso_prec_rec, bbox_prec_rec, imglist, bbox_models, ...
							C, stage2model);


